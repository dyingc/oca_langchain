# 请将以下值替换为您的真实凭证和配置

# --- OAuth2 认证配置 ---
OAUTH_HOST=""
OAUTH_CLIENT_ID=""
OAUTH_REFRESH_TOKEN=""

# --- LLM API 配置 ---
# 这是您的语言模型API的端点URL (例如: https://api.your-provider.com/v1/chat/completions)
LLM_API_URL=""

# 要使用的模型名称
LLM_MODEL_NAME=""

# 获取可用模型列表的 API 端点
LLM_MODELS_API_URL=""

# 默认的系统提示 (System Prompt)
LLM_SYSTEM_PROMPT="You are a helpful assistant."

# 默认的采样温度 (0.0 到 2.0 之间)
LLM_TEMPERATURE="0.7"

# --- 网络配置 ---
# 如果应用无法直接访问 OAuth 或 LLM API，请在此处指定 HTTP 代理服务器的地址
# 例如: http://user:password@proxy.example.com:8080
HTTP_PROXY_URL=""
